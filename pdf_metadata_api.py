# -*- coding: utf-8 -*-
"""
PDFå…ƒæ•°æ®æå–ç³»ç»Ÿ - Flask APIåç«¯
è½»é‡åŒ–è®¾è®¡ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—
"""

import os
import json
import uuid
import asyncio
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import asdict
from pathlib import Path

from flask import Flask, request, jsonify, Response, render_template, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename
import pandas as pd

# å¯¼å…¥ç°æœ‰çš„å…ƒæ•°æ®æå–æ¨¡å—
from Metadata import extract_first_page_llm, PaperMeta, extract_acknowledgment_from_last_pages
from concurrent_processor import get_global_processor, ConcurrentProcessor, RateLimitConfig

# =========================
# é…ç½®ç®¡ç†ç±»
# =========================
class Config:
    """åº”ç”¨é…ç½®ç®¡ç†"""
    UPLOAD_FOLDER = 'uploads'
    RESULTS_FOLDER = 'results'
    MAX_CONTENT_LENGTH = 2 * 1024 * 1024 * 1024  # 2GB
    ALLOWED_EXTENSIONS = {'pdf'}
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    @classmethod
    def init_directories(cls):
        for folder in [cls.UPLOAD_FOLDER, cls.RESULTS_FOLDER]:
            Path(folder).mkdir(exist_ok=True)

# =========================
# æ•°æ®å¤„ç†å™¨ç±»
# =========================
class MetadataProcessor:
    """å…ƒæ•°æ®å¤„ç†å™¨ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘"""
    
    def __init__(self):
        self.processing_tasks = {}
    
    async def process_file(self, file_path: str, mode: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªPDFæ–‡ä»¶"""
        try:
            # è°ƒç”¨ç°æœ‰çš„å…ƒæ•°æ®æå–å‡½æ•°
            meta = await extract_first_page_llm(file_path)
            
            # æ ¹æ®æ¨¡å¼è½¬æ¢æ•°æ®æ ¼å¼
            if mode == 'sn':
                return self._format_sn_data(meta, file_path)
            elif mode == 'ieee':
                return self._format_ieee_data(meta, file_path)
            elif mode == 'funding':
                return self._format_funding_data(meta, file_path)
            elif mode == 'ap':
                return self._format_ap_data(meta, file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")
                
        except Exception as e:
            filename = os.path.splitext(os.path.basename(file_path))[0]
            return {
                'error': str(e),
                'file': file_path,
                'filename': filename,
                # æ ¹æ®æ¨¡å¼æ·»åŠ å¯¹åº”çš„æ–‡ä»¶åå­—æ®µ
                'æ–‡ä»¶å': filename,  # èµ„åŠ©ä¿¡æ¯å’ŒAPæ¨¡å¼
                'Number': filename,  # SNæ¨¡å¼
                'è®¢å•å·': filename,  # IEEEæ¨¡å¼
                'status': 'failed'
            }
    
    def _format_sn_data(self, meta: PaperMeta, file_path: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–SNæ¨¡å¼æ•°æ®"""
        filename = os.path.splitext(os.path.basename(file_path))[0]
        result = {
            'Number': filename,
            'Title': meta.title,
            'SubTitle': '',  # éœ€è¦ä»æ ‡é¢˜ä¸­åˆ†ç¦»å‰¯æ ‡é¢˜
            'Corresponding Author': '',
            "Corresponding author's email": '',
            'filename': filename  # æ·»åŠ é€šç”¨filenameå­—æ®µ
        }
        
        # å¤„ç†ä½œè€…ä¿¡æ¯
        for i, author in enumerate(meta.authors[:5], 1):
            result[f'Author {i}'] = author.name
            result[f'Affiliation {i}'] = next(
                (aff.name for aff in meta.affiliations if aff.id in author.affiliation_ids),
                ''
            )
            
            # è¯†åˆ«é€šè®¯ä½œè€…
            if author.is_corresponding_author:
                result['Corresponding Author'] = author.name
                result["Corresponding author's email"] = author.email or ''
        
        # å¦‚æœæ²¡æœ‰æ ‡è®°é€šè®¯ä½œè€…ï¼Œä½¿ç”¨ç¬¬ä¸€ä½œè€…
        if not result['Corresponding Author'] and meta.authors:
            result['Corresponding Author'] = meta.authors[0].name
            result["Corresponding author's email"] = meta.authors[0].email or ''
        
        return result
    
    def _format_ieee_data(self, meta: PaperMeta, file_path: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–IEEEæ¨¡å¼æ•°æ®"""
        # æå–æ‰€æœ‰ä½œè€…å§“åï¼Œå»é™¤ä¸Šæ ‡
        all_authors = ', '.join([author.name for author in meta.authors])
        
        # è·å–ç¬¬ä¸€ä½œè€…é‚®ç®±ï¼Œå¦‚æœæ²¡æœ‰åˆ™å–é€šè®¯ä½œè€…é‚®ç®±
        first_author_email = ''
        if meta.authors:
            first_author_email = meta.authors[0].email or ''
            if not first_author_email:
                # æŸ¥æ‰¾é€šè®¯ä½œè€…é‚®ç®±
                for author in meta.authors:
                    if author.is_corresponding_author and author.email:
                        first_author_email = author.email
                        break
        
        filename = os.path.splitext(os.path.basename(file_path))[0]
        return {
            'è®¢å•å·': filename,
            'è‹±æ–‡é¢˜ç›®': meta.title,
            'è‹±æ–‡å‰¯æ ‡': '',  # éœ€è¦ä»æ ‡é¢˜ä¸­åˆ†ç¦»
            'ä½œè€…å§“å': all_authors,
            'ç¬¬ä¸€ä½œè€…é‚®ç®±': first_author_email,
            'filename': filename  # æ·»åŠ é€šç”¨filenameå­—æ®µ
        }
    
    def _format_funding_data(self, meta: PaperMeta, file_path: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–èµ„åŠ©ä¿¡æ¯æ¨¡å¼æ•°æ®"""
        first_author = meta.authors[0] if meta.authors else None
        corresponding_author = next(
            (author for author in meta.authors if author.is_corresponding_author),
            first_author
        )

        # æå–è‡´è°¢ä¿¡æ¯
        acknowledgment = ""
        try:
            acknowledgment = extract_acknowledgment_from_last_pages(file_path)
        except Exception as e:
            print(f"è‡´è°¢ä¿¡æ¯æå–å¤±è´¥: {e}")

        filename = os.path.splitext(os.path.basename(file_path))[0]
        return {
            'æ–‡ä»¶å': filename,
            'è®ºæ–‡è‹±æ–‡é¢˜ç›®': meta.title,
            'ç¬¬ä¸€ä½œè€…å§“å': first_author.name if first_author else '',
            'ç¬¬ä¸€ä½œè€…å•ä½': self._get_author_affiliation(first_author, meta.affiliations) if first_author else '',
            'é€šè®¯ä½œè€…å§“å': corresponding_author.name if corresponding_author else '',
            'é€šè®¯ä½œè€…å•ä½': self._get_author_affiliation(corresponding_author, meta.affiliations) if corresponding_author else '',
            'é€šè®¯ä½œè€…é‚®ç®±': corresponding_author.email if corresponding_author else '',
            'å…³é”®è¯': ', '.join(meta.keywords),
            'æ‘˜è¦': meta.abstract or '',
            'è‡´è°¢': acknowledgment,
            'filename': filename  # æ·»åŠ é€šç”¨filenameå­—æ®µ
        }
    
    def _format_ap_data(self, meta: PaperMeta, file_path: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–APæ¨¡å¼æ•°æ®"""
        first_author = meta.authors[0] if meta.authors else None
        corresponding_author = next(
            (author for author in meta.authors if author.is_corresponding_author),
            None
        )
        
        filename = os.path.splitext(os.path.basename(file_path))[0]
        result = {
            'é¢˜ç›®': meta.title,
            'å…³é”®è¯': ', '.join(meta.keywords),
            'æ‘˜è¦': meta.abstract or '',
            'æ–‡ä»¶å': filename,
            'filename': filename  # æ·»åŠ é€šç”¨filenameå­—æ®µ
        }
        
        # ç¬¬ä¸€ä½œè€…å§“ååˆ†è§£
        if first_author:
            name_parts = first_author.name.split()
            result['ç¬¬ä¸€ä½œè€…å§“'] = name_parts[-1] if name_parts else ''
            result['ç¬¬ä¸€ä½œè€…å'] = ' '.join(name_parts[:-1]) if len(name_parts) > 1 else ''
        
        # é€šè®¯ä½œè€…å§“ååˆ†è§£ï¼ˆä»…å½“é€šè®¯ä½œè€…éç¬¬ä¸€ä½œè€…æ—¶ï¼‰
        if corresponding_author and corresponding_author != first_author:
            name_parts = corresponding_author.name.split()
            result['é€šè®¯ä½œè€…å§“'] = name_parts[-1] if name_parts else ''
            result['é€šè®¯ä½œè€…å'] = ' '.join(name_parts[:-1]) if len(name_parts) > 1 else ''
        
        return result
    
    def _get_author_affiliation(self, author, affiliations) -> str:
        """è·å–ä½œè€…å•ä½"""
        if not author or not author.affiliation_ids:
            return ''
        
        for aff_id in author.affiliation_ids:
            aff = next((aff for aff in affiliations if aff.id == aff_id), None)
            if aff:
                return aff.name
        return ''

# =========================
# Flaskåº”ç”¨åˆå§‹åŒ–
# =========================
app = Flask(__name__)
app.config.from_object(Config)
CORS(app)

# åˆå§‹åŒ–ç»„ä»¶
Config.init_directories()
processor = MetadataProcessor()

def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•å"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in Config.ALLOWED_EXTENSIONS

# =========================
# APIè·¯ç”±å®šä¹‰
# =========================

@app.route('/')
def index():
    """ä¸»é¡µ - è¿”å›å‰ç«¯ç•Œé¢"""
    return render_template('PDF.html')

@app.route('/favicon.ico')
def favicon():
    """Favicon"""
    return '', 204

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@app.route('/api/upload', methods=['POST'])
def upload_files():
    """æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    try:
        files = request.files.getlist('files')
        if not files:
            return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400

        uploaded_files = []
        for file in files:
            if file and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                file_id = str(uuid.uuid4())
                file_path = os.path.join(Config.UPLOAD_FOLDER, f"{file_id}_{filename}")
                file.save(file_path)

                uploaded_files.append({
                    'file_id': file_id,
                    'filename': filename,
                    'path': file_path,
                    'size': os.path.getsize(file_path)
                })

        return jsonify({
            'success': True,
            'files': uploaded_files,
            'count': len(uploaded_files)
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/files', methods=['GET'])
def list_files():
    """è·å–å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨"""
    try:
        files = []
        upload_dir = Path(Config.UPLOAD_FOLDER)

        for file_path in upload_dir.glob('*.pdf'):
            stat = file_path.stat()
            files.append({
                'filename': file_path.name,
                'size': stat.st_size,
                'upload_time': datetime.fromtimestamp(stat.st_ctime).isoformat()
            })

        return jsonify({
            'files': files,
            'count': len(files)
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/files/<file_id>', methods=['DELETE'])
def delete_file(file_id):
    """åˆ é™¤æŒ‡å®šæ–‡ä»¶"""
    try:
        upload_dir = Path(Config.UPLOAD_FOLDER)
        file_pattern = f"{file_id}_*"

        deleted = False
        for file_path in upload_dir.glob(file_pattern):
            file_path.unlink()
            deleted = True

        if deleted:
            return jsonify({'success': True, 'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/extract/<mode>', methods=['POST'])
def extract_metadata(mode):
    """å•æ¨¡å¼å…ƒæ•°æ®æå–æ¥å£ï¼ˆæ”¯æŒå¹¶å‘å¤„ç†ï¼‰"""
    try:
        if mode not in ['sn', 'ieee', 'funding', 'ap']:
            return jsonify({'error': f'ä¸æ”¯æŒçš„æ¨¡å¼: {mode}'}), 400

        data = request.get_json()
        file_paths = data.get('file_paths', [])
        use_concurrent = data.get('use_concurrent', len(file_paths) > 5)  # è¶…è¿‡5ä¸ªæ–‡ä»¶è‡ªåŠ¨å¯ç”¨å¹¶å‘

        if not file_paths:
            return jsonify({'error': 'æ²¡æœ‰æŒ‡å®šæ–‡ä»¶è·¯å¾„'}), 400

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        valid_files = []
        invalid_files = []
        for file_path in file_paths:
            if os.path.exists(file_path):
                valid_files.append(file_path)
            else:
                invalid_files.append({
                    'file': file_path,
                    'error': 'æ–‡ä»¶ä¸å­˜åœ¨',
                    'status': 'failed'
                })

        if not valid_files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„',
                'results': invalid_files
            }), 400

        # é€‰æ‹©å¤„ç†æ–¹å¼
        if use_concurrent and len(valid_files) > 1:
            # å¹¶å‘å¤„ç†
            concurrent_processor = get_global_processor()

            async def process_wrapper(file_path: str, mode: str):
                return await processor.process_file(file_path, mode)

            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                results = loop.run_until_complete(
                    concurrent_processor.process_batch(valid_files, process_wrapper, mode)
                )
            finally:
                loop.close()
        else:
            # ä¸²è¡Œå¤„ç†
            results = []
            for file_path in valid_files:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(processor.process_file(file_path, mode))
                    results.append(result)
                finally:
                    loop.close()

        # åˆå¹¶æ— æ•ˆæ–‡ä»¶ç»“æœ
        all_results = results + invalid_files
        successful_count = len([r for r in results if r.get('status') != 'failed' and 'error' not in r])

        return jsonify({
            'success': True,
            'mode': mode,
            'results': all_results,
            'count': len(all_results),
            'successful': successful_count,
            'failed': len(all_results) - successful_count,
            'concurrent_used': use_concurrent and len(valid_files) > 1
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/extract/batch', methods=['POST'])
def extract_batch():
    """ä¸“é—¨çš„æ‰¹é‡å¤„ç†ç«¯ç‚¹ï¼ˆä¼˜åŒ–å¤§æ–‡ä»¶å¤„ç†ï¼‰"""
    try:
        data = request.get_json()
        file_paths = data.get('file_paths', [])
        mode = data.get('mode', 'sn')

        if mode not in ['sn', 'ieee', 'funding', 'ap']:
            return jsonify({'error': f'ä¸æ”¯æŒçš„æ¨¡å¼: {mode}'}), 400

        if not file_paths:
            return jsonify({'error': 'æ²¡æœ‰æŒ‡å®šæ–‡ä»¶è·¯å¾„'}), 400

        if len(file_paths) > 200:
            return jsonify({'error': 'å•æ¬¡æœ€å¤šå¤„ç†200ä¸ªæ–‡ä»¶'}), 400

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        valid_files = [f for f in file_paths if os.path.exists(f)]
        invalid_count = len(file_paths) - len(valid_files)

        if not valid_files:
            return jsonify({'error': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„'}), 400

        # ä½¿ç”¨å¹¶å‘å¤„ç†å™¨
        concurrent_processor = get_global_processor()

        async def process_wrapper(file_path: str, mode: str):
            return await processor.process_file(file_path, mode)

        # è¿›åº¦è·Ÿè¸ª
        progress_info = {'current': 0, 'total': len(valid_files), 'message': 'å‡†å¤‡ä¸­...'}

        async def progress_callback(progress: float, message: str):
            progress_info['current'] = int(progress * len(valid_files) / 100)
            progress_info['message'] = message

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            start_time = time.time()
            results = loop.run_until_complete(
                concurrent_processor.process_batch(valid_files, process_wrapper, mode, progress_callback)
            )
            processing_time = time.time() - start_time
        finally:
            loop.close()

        # ç»Ÿè®¡ç»“æœ
        successful_count = len([r for r in results if r.get('status') != 'failed' and 'error' not in r])
        failed_count = len(results) - successful_count

        # è·å–å¤„ç†ç»Ÿè®¡
        stats = concurrent_processor.get_processing_stats()

        return jsonify({
            'success': True,
            'mode': mode,
            'results': results,
            'statistics': {
                'total_files': len(file_paths),
                'valid_files': len(valid_files),
                'invalid_files': invalid_count,
                'successful': successful_count,
                'failed': failed_count,
                'success_rate': (successful_count / len(valid_files)) * 100 if valid_files else 0,
                'processing_time': round(processing_time, 2),
                'avg_time_per_file': round(processing_time / len(valid_files), 2) if valid_files else 0
            },
            'rate_limit_stats': stats
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/processing/stats', methods=['GET'])
def get_processing_stats():
    """è·å–å½“å‰å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        concurrent_processor = get_global_processor()
        stats = concurrent_processor.get_processing_stats()

        return jsonify({
            'success': True,
            'stats': stats,
            'timestamp': time.time()
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/extract/batch', methods=['POST'])
def batch_extract():
    """æ‰¹é‡å¤„ç†å¤šç§æ¨¡å¼"""
    try:
        data = request.get_json()
        file_paths = data.get('file_paths', [])
        modes = data.get('modes', ['sn'])

        if not file_paths:
            return jsonify({'error': 'æ²¡æœ‰æŒ‡å®šæ–‡ä»¶è·¯å¾„'}), 400

        results = {}
        for mode in modes:
            if mode not in ['sn', 'ieee', 'funding', 'ap']:
                continue

            mode_results = []
            for file_path in file_paths:
                if not os.path.exists(file_path):
                    mode_results.append({
                        'file': file_path,
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨',
                        'status': 'failed'
                    })
                    continue

                # å¼‚æ­¥å¤„ç†æ–‡ä»¶
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(processor.process_file(file_path, mode))
                    mode_results.append(result)
                finally:
                    loop.close()

            results[mode] = mode_results

        return jsonify({
            'success': True,
            'results': results,
            'processed_modes': list(results.keys())
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/process', methods=['POST'])
def process_files():
    """å¤„ç†PDFæ–‡ä»¶çš„ä¸»æ¥å£ï¼ˆæµå¼å“åº”ï¼‰"""
    def generate():
        try:
            # è·å–ä¸Šä¼ çš„æ–‡ä»¶å’Œæ¨¡å¼
            files = request.files.getlist('files')
            mode = request.form.get('mode', 'sn')

            if not files:
                yield json.dumps({'type': 'error', 'message': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}) + '\n'
                return

            yield json.dumps({
                'type': 'status',
                'message': f'å¼€å§‹å¤„ç† {len(files)} ä¸ªæ–‡ä»¶ï¼Œæ¨¡å¼: {mode}'
            }) + '\n'

            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            saved_files = []
            for file in files:
                if file and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_path = os.path.join(Config.UPLOAD_FOLDER, filename)
                    file.save(file_path)
                    saved_files.append(file_path)

            yield json.dumps({
                'type': 'info',
                'message': f'æˆåŠŸä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶'
            }) + '\n'

            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            for i, file_path in enumerate(saved_files, 1):
                yield json.dumps({
                    'type': 'status',
                    'message': f'æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(saved_files)} ä¸ªæ–‡ä»¶: {os.path.basename(file_path)}'
                }) + '\n'

                # å¼‚æ­¥å¤„ç†æ–‡ä»¶
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(processor.process_file(file_path, mode))

                    if 'error' not in result:
                        yield json.dumps({
                            'type': 'data_row',
                            'data': result
                        }) + '\n'

                        yield json.dumps({
                            'type': 'success',
                            'message': f'âœ… {os.path.basename(file_path)} å¤„ç†å®Œæˆ'
                        }) + '\n'
                    else:
                        yield json.dumps({
                            'type': 'error',
                            'message': f'âŒ {os.path.basename(file_path)} å¤„ç†å¤±è´¥: {result["error"]}'
                        }) + '\n'

                finally:
                    loop.close()

            yield json.dumps({
                'type': 'status',
                'message': 'æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ'
            }) + '\n'

        except Exception as e:
            yield json.dumps({
                'type': 'error',
                'message': f'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}'
            }) + '\n'

    return Response(generate(), mimetype='text/plain')

@app.route('/api/export/excel', methods=['POST'])
def export_excel():
    """å¯¼å‡ºExcelæ ¼å¼ç»“æœ"""
    try:
        data = request.get_json()
        results = data.get('results', [])
        mode = data.get('mode', 'sn')

        if not results:
            return jsonify({'error': 'æ²¡æœ‰æ•°æ®å¯å¯¼å‡º'}), 400

        # åˆ›å»ºDataFrame
        df = pd.DataFrame(results)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{mode}_metadata_{timestamp}.xlsx"
        file_path = os.path.join(Config.RESULTS_FOLDER, filename)

        # ä¿å­˜Excelæ–‡ä»¶
        df.to_excel(file_path, index=False, engine='openpyxl')

        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export/json', methods=['POST'])
def export_json():
    """å¯¼å‡ºJSONæ ¼å¼ç»“æœ"""
    try:
        data = request.get_json()
        results = data.get('results', [])
        mode = data.get('mode', 'sn')

        if not results:
            return jsonify({'error': 'æ²¡æœ‰æ•°æ®å¯å¯¼å‡º'}), 400

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{mode}_metadata_{timestamp}.json"
        file_path = os.path.join(Config.RESULTS_FOLDER, filename)

        # ä¿å­˜JSONæ–‡ä»¶
        export_data = {
            'mode': mode,
            'export_time': datetime.now().isoformat(),
            'count': len(results),
            'results': results
        }

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)

        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='application/json'
        )

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/progress/<task_id>', methods=['GET'])
def get_progress(task_id):
    """è·å–å¤„ç†è¿›åº¦"""
    try:
        task_info = processor.processing_tasks.get(task_id)
        if not task_info:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        return jsonify(task_info)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

# =========================
# é”™è¯¯å¤„ç†
# =========================
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'æ¥å£ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@app.errorhandler(413)
def too_large(error):
    return jsonify({'error': 'æ–‡ä»¶è¿‡å¤§'}), 413

# =========================
# åº”ç”¨å¯åŠ¨
# =========================
if __name__ == '__main__':
    print("ğŸš€ PDFå…ƒæ•°æ®æå–ç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("ğŸ“Š æ”¯æŒçš„æå–æ¨¡å¼: SN, IEEE, èµ„åŠ©ä¿¡æ¯, AP")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸ“ ä¸Šä¼ ç›®å½•:", Config.UPLOAD_FOLDER)
    print("ğŸ“ ç»“æœç›®å½•:", Config.RESULTS_FOLDER)
    print("\nğŸ”— APIæ¥å£åˆ—è¡¨:")
    print("  GET  /                     - ä¸»é¡µç•Œé¢")
    print("  GET  /api/health           - å¥åº·æ£€æŸ¥")
    print("  POST /api/upload           - æ–‡ä»¶ä¸Šä¼ ")
    print("  GET  /api/files            - æ–‡ä»¶åˆ—è¡¨")
    print("  DEL  /api/files/<id>       - åˆ é™¤æ–‡ä»¶")
    print("  POST /api/extract/<mode>   - å•æ¨¡å¼æå–")
    print("  POST /api/extract/batch    - æ‰¹é‡æå–")
    print("  POST /api/export/excel     - å¯¼å‡ºExcel")
    print("  POST /api/export/json      - å¯¼å‡ºJSON")
    print("  POST /process              - æµå¼å¤„ç†")
    print("\nâœ¨ ç³»ç»Ÿå°±ç»ªï¼Œç­‰å¾…è¯·æ±‚...")

    app.run(debug=True, host='0.0.0.0', port=5000)
